{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "import torch.utils.data.dataloader as DataLoader\n",
    "\n",
    "from pl_bolts.models.self_supervised import SimCLR\n",
    "from pl_bolts.datamodules import ImagenetDataModule\n",
    "\n",
    "from pl_bolts.models.self_supervised.simclr \\\n",
    "    import SimCLRTrainDataTransform\n",
    "from pl_bolts.models.self_supervised.simclr \\\n",
    "    import SimCLREvalDataTransform\n",
    "\n",
    "\n",
    "# Pytorch and Torchvision Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.optim import Adam\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dsets.ImageFolder(\n",
    "    root=data_dir,\n",
    "    transform=SimCLRTrainDataTransform(input_height=512)\n",
    ")\n",
    "dataloader = data.DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rayno\\AppData\\Local\\Temp\\ipykernel_19280\\2045871004.py:2: UnderReviewWarning: The feature SimCLR is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  model = SimCLR( gpus=-1, batch_size=BATCH_SIZE, dataset=data_dir, num_samples=6000)\n",
      "D:\\cs198\\SIMCLR\\simclr\\lib\\site-packages\\pl_bolts\\models\\self_supervised\\simclr\\simclr_module.py:138: UnderReviewWarning: The feature resnet50 is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  return backbone(first_conv=self.first_conv, maxpool1=self.maxpool1, return_all_feature_maps=False)\n",
      "D:\\cs198\\SIMCLR\\simclr\\lib\\site-packages\\pl_bolts\\models\\self_supervised\\resnets.py:321: UnderReviewWarning: The feature _resnet is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  return _resnet(\"resnet50\", Bottleneck, [3, 4, 6, 3], pretrained, progress, **kwargs)\n",
      "D:\\cs198\\SIMCLR\\simclr\\lib\\site-packages\\pl_bolts\\models\\self_supervised\\resnets.py:281: UnderReviewWarning: The feature ResNet is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  model = ResNet(block, layers, **kwargs)\n",
      "D:\\cs198\\SIMCLR\\simclr\\lib\\site-packages\\pl_bolts\\models\\self_supervised\\resnets.py:223: UnderReviewWarning: The feature conv1x1 is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  conv1x1(self.inplanes, planes * block.expansion, stride),\n",
      "D:\\cs198\\SIMCLR\\simclr\\lib\\site-packages\\pl_bolts\\models\\self_supervised\\resnets.py:229: UnderReviewWarning: The feature Bottleneck is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  block(\n",
      "D:\\cs198\\SIMCLR\\simclr\\lib\\site-packages\\pl_bolts\\models\\self_supervised\\resnets.py:110: UnderReviewWarning: The feature conv3x3 is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
      "D:\\cs198\\SIMCLR\\simclr\\lib\\site-packages\\pl_bolts\\models\\self_supervised\\simclr\\simclr_module.py:126: UnderReviewWarning: The feature Projection is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.projection = Projection(input_dim=self.hidden_mlp, hidden_dim=self.hidden_mlp, output_dim=self.feat_dim)\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=64\n",
    "model = SimCLR( gpus=-1, batch_size=BATCH_SIZE, dataset=data_dir, num_samples=6000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Epochs: 5\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    # Use deterministic cudnn algorithms\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    epochs = 10\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    epochs = 5\n",
    "\n",
    "print(\"Device: {}\".format(device))\n",
    "print(\"Epochs: {}\".format(epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <function _is_device_tpu at 0x000002890F3F14C0>: it's not the same object as lightning_lite.accelerators.tpu._is_device_tpu",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(dataloader)\n",
      "File \u001b[1;32mD:\\cs198\\SIMCLR\\simclr\\lib\\site-packages\\pytorch_lightning\\utilities\\argparse.py:340\u001b[0m, in \u001b[0;36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    337\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mlist\u001b[39m(env_variables\u001b[38;5;241m.\u001b[39mitems()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mitems()))\n\u001b[0;32m    339\u001b[0m \u001b[38;5;66;03m# all args were already moved to kwargs\u001b[39;00m\n\u001b[1;32m--> 340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\cs198\\SIMCLR\\simclr\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:501\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[1;34m(self, logger, enable_checkpointing, callbacks, default_root_dir, gradient_clip_val, gradient_clip_algorithm, num_nodes, num_processes, devices, gpus, auto_select_gpus, tpu_cores, ipus, enable_progress_bar, overfit_batches, track_grad_norm, check_val_every_n_epoch, fast_dev_run, accumulate_grad_batches, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, val_check_interval, log_every_n_steps, accelerator, strategy, sync_batchnorm, precision, enable_model_summary, num_sanity_val_steps, resume_from_checkpoint, profiler, benchmark, deterministic, reload_dataloaders_every_n_epochs, auto_lr_find, replace_sampler_ddp, detect_anomaly, auto_scale_batch_size, plugins, amp_backend, amp_level, move_metrics_to_cpu, multiple_trainloader_mode, inference_mode)\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_mode: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m inference_mode\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m detect_anomaly\n\u001b[1;32m--> 501\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_on_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;66;03m# configure tuner\u001b[39;00m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtuner\u001b[38;5;241m.\u001b[39mon_trainer_init(auto_lr_find, auto_scale_batch_size)\n",
      "File \u001b[1;32mD:\\cs198\\SIMCLR\\simclr\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:534\u001b[0m, in \u001b[0;36mTrainer._setup_on_init\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_setup_on_init\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 534\u001b[0m     \u001b[43msetup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_device_info\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m TrainerState()\n",
      "File \u001b[1;32mD:\\cs198\\SIMCLR\\simclr\\lib\\site-packages\\pytorch_lightning\\trainer\\setup.py:165\u001b[0m, in \u001b[0;36m_log_device_info\u001b[1;34m(trainer)\u001b[0m\n\u001b[0;32m    162\u001b[0m rank_zero_info(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU available: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgpu_available\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mgpu_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, used: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgpu_used\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    164\u001b[0m num_tpu_cores \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mnum_devices \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(trainer\u001b[38;5;241m.\u001b[39maccelerator, TPUAccelerator) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 165\u001b[0m rank_zero_info(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTPU available: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTPUAccelerator\u001b[38;5;241m.\u001b[39mis_available()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, using: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_tpu_cores\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m TPU cores\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    167\u001b[0m num_ipus \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mnum_devices \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(trainer\u001b[38;5;241m.\u001b[39maccelerator, IPUAccelerator) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    168\u001b[0m rank_zero_info(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPU available: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_IPU_AVAILABLE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, using: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_ipus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m IPUs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\cs198\\SIMCLR\\simclr\\lib\\site-packages\\pytorch_lightning\\accelerators\\tpu.py:77\u001b[0m, in \u001b[0;36mTPUAccelerator.is_available\u001b[1;34m()\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_available\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLiteTPUAccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\cs198\\SIMCLR\\simclr\\lib\\site-packages\\lightning_lite\\accelerators\\tpu.py:62\u001b[0m, in \u001b[0;36mTPUAccelerator.is_available\u001b[1;34m()\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache(maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_available\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# check `_XLA_AVAILABLE` again to avoid launching processes\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(_XLA_AVAILABLE) \u001b[38;5;129;01mand\u001b[39;00m \u001b[43m_is_device_tpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\cs198\\SIMCLR\\simclr\\lib\\site-packages\\lightning_lite\\accelerators\\tpu.py:90\u001b[0m, in \u001b[0;36m_multi_process.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     88\u001b[0m queue: Queue \u001b[38;5;241m=\u001b[39m Queue()\n\u001b[0;32m     89\u001b[0m proc \u001b[38;5;241m=\u001b[39m Process(target\u001b[38;5;241m=\u001b[39m_inner_f, args\u001b[38;5;241m=\u001b[39m(queue, func, \u001b[38;5;241m*\u001b[39margs), kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m---> 90\u001b[0m \u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m proc\u001b[38;5;241m.\u001b[39mjoin(TPU_CHECK_TIMEOUT)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Program Files\\Python38\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\Python38\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\Python38\\lib\\multiprocessing\\context.py:327\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\Python38\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Program Files\\Python38\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mPicklingError\u001b[0m: Can't pickle <function _is_device_tpu at 0x000002890F3F14C0>: it's not the same object as lightning_lite.accelerators.tpu._is_device_tpu"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(accelerator=\"cpu\")\n",
    "trainer.fit(dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simclr",
   "language": "python",
   "name": "simclr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
